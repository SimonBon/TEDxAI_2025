{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mmengine.registry import build_model_from_cfg\n",
    "from mmselfsup.registry import MODELS\n",
    "from mmselfsup.utils import register_all_modules\n",
    "from mmengine.runner import Runner\n",
    "from mmengine.config import Config\n",
    "\n",
    "import torch\n",
    "torch.cuda.set_device(2)  # all `.cuda()` calls default to GPU 1 now\n",
    "\n",
    "# your custom modules\n",
    "import src.losses\n",
    "import src.mvsimclr\n",
    "import src.dataset\n",
    "import src.transforms\n",
    "import torch\n",
    "\n",
    "register_all_modules()\n",
    "\n",
    "cfg = Config.fromfile('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/TEDxAI_2025/config.py').to_dict()\n",
    "model = build_model_from_cfg(cfg['model'], MODELS)\n",
    "checkpoint = torch.load('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/TEDxAI_2025/model.pth', map_location='cpu')\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "model = model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from FISHPainter_package.FISHPainter.src.datasets.create import create_dataset\n",
    "import numpy as np\n",
    "from cellplot.patches import gridPlot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = create_dataset(\n",
    "    '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/FISHPainter_package/configs/MYCN.yml',\n",
    "    FISH_type='COPY_NUMBER',\n",
    "    background_path=None,\n",
    "    verbose=True,\n",
    "    merge_bboxes=False,\n",
    "    alpha=15,\n",
    "    sigma=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "patches, masks, parameters, target = [], [], [], [] \n",
    "for key, values in dataset.items():\n",
    "    patches.extend(values['rgb_patches'])\n",
    "    masks.extend(values['masks'])\n",
    "    parameters.extend(values['parameters'])\n",
    "    target.extend(values['target_classes'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gridPlot(patches, hspace=-0.01, vspace=-0.01, plot_size=(20,20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = np.array(parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File('/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/DiagnosticFISH/test_dataset.h5', 'w') as f:\n",
    "    f.create_dataset('FISH', data=np.array(patches))\n",
    "    f.create_dataset('NUCLEUS', data=np.array(masks))\n",
    "    f.create_dataset('N_SIGNALS', data=np.vstack((parameters[:, 0], parameters[:, 3])).T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images, masks = [], []\n",
    "for k, v in dataset.items():\n",
    "    images.extend(v['rgb_patches'])\n",
    "    masks.extend(v['masks'])\n",
    "    \n",
    "images = np.array(images)\n",
    "masks = np.array(masks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.spatial.distance import cdist\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def randomly_place_cells(out_size, rgb_images, mask_images, n_images, max_rejections=10, margin=1.1):\n",
    "    \n",
    "    hpsz = rgb_images.shape[1] // 2  \n",
    "    out_image = np.zeros([*np.array(out_size) + 2*hpsz, 3])\n",
    "    mask_image = np.zeros([*np.array(out_size) + 2*hpsz])\n",
    "    \n",
    "    rejection_count = 0  # Counter for consecutive rejections\n",
    "    placed_cells = 0\n",
    "    placed_idxs, placed_pos = [], []\n",
    "    # Loop until all cells are placed or too many rejections occur\n",
    "    while placed_cells < n_images:\n",
    "        # Randomly select a cell and calculate its diameter\n",
    "        if rejection_count == max_rejections:\n",
    "            print(f'reached max rejections after {placed_cells} cells')\n",
    "            break\n",
    "        \n",
    "        cell_index = np.random.choice(len(rgb_images))\n",
    "\n",
    "        # Generate a random position\n",
    "        try_pos = [np.random.randint(hpsz, out_size[0] + hpsz), np.random.randint(hpsz, out_size[1] + hpsz)]\n",
    "        \n",
    "        if mask_image[try_pos[0], try_pos[1]] == 1:\n",
    "            rejection_count += 1 \n",
    "            continue\n",
    "\n",
    "        # Check if the new position overlaps with any existing cell\n",
    "        tmp = np.zeros_like(mask_image)\n",
    "        rot = np.random.randint(3)\n",
    "        tmp[try_pos[0]-hpsz:try_pos[0]+hpsz, try_pos[1]-hpsz:try_pos[1]+hpsz] = np.rot90(mask_images[cell_index], k=rot)\n",
    "        if np.any((mask_image + tmp) > 1):\n",
    "            rejection_count += 1 \n",
    "            continue\n",
    "        \n",
    "        mask_image = mask_image + tmp\n",
    "        \n",
    "        out_image[\n",
    "            try_pos[0]-hpsz:try_pos[0]+hpsz,\n",
    "            try_pos[1]-hpsz:try_pos[1]+hpsz\n",
    "        ] += np.rot90(rgb_images[cell_index], k=rot)\n",
    "\n",
    "        placed_cells += 1\n",
    "        \n",
    "        placed_idxs.append(cell_index)\n",
    "        placed_pos.append([try_pos[0]-hpsz, try_pos[1]-hpsz])\n",
    "\n",
    "    return np.clip(out_image[hpsz:-hpsz, hpsz:-hpsz], 0, 1), placed_idxs, placed_pos\n",
    "\n",
    "# Example Usage\n",
    "\n",
    "# Assuming `rgb_images` and `mask_images` are provided as lists of arrays"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiagnosticFISH_package.DiagnosticFISH.src.utils import get_model_dataloader, run_model\n",
    "from DiagnosticFISH_package.DiagnosticFISH.src.dataset import SingleChannelDataset\n",
    "from mmengine.dataset import DefaultSampler, default_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from mmselfsup.datasets.transforms import PackSelfSupInputs\n",
    "from DiagnosticFISH_package.DiagnosticFISH.src.transforms import CentralCutter, C_TensorCombiner\n",
    "\n",
    "\n",
    "cuda = 'cuda:2'\n",
    "\n",
    "model, _, _ = get_model_dataloader(\n",
    "    \"/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/mmselfsup_package/tools/work_dirs/home/config\", \n",
    "    num_worker=16,\n",
    "    batch_size=64,\n",
    "    device=cuda,\n",
    "    meta_keys=['n_signals', 'size_nucleus'],\n",
    ")\n",
    "\n",
    "pipeline = [\n",
    "    C_TensorCombiner(),\n",
    "    CentralCutter(size=128), \n",
    "    PackSelfSupInputs(meta_keys=[])\n",
    "]\n",
    "\n",
    "dataset = SingleChannelDataset(\n",
    "    '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/DiagnosticFISH/classifier_dataset.h5',\n",
    "    shuffle=False,\n",
    "    pipeline=pipeline,\n",
    "    channel_idx=1)\n",
    "\n",
    "dataloader = DataLoader(\n",
    "        dataset=dataset, \n",
    "        sampler=DefaultSampler(dataset, shuffle=False), \n",
    "        batch_size=64, \n",
    "        collate_fn=default_collate,\n",
    "        num_workers=16\n",
    "    )\n",
    "\n",
    "model.eval();\n",
    "\n",
    "ret = run_model(model, dataloader, n_samples=10_000, get_images=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "\n",
    "# **1️⃣ Create a Simple Binary Classifier**\n",
    "class BinaryClassifier(nn.Module):\n",
    "    def __init__(self, input_size=2048):\n",
    "        super(BinaryClassifier, self).__init__()\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 1),\n",
    "            nn.Sigmoid()  # Output probability between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "# **2️⃣ Generate Dummy Data**\n",
    "X = torch.tensor(np.array(ret['embeddings'].tolist()).mean(axis=(2,3)))\n",
    "y = torch.tensor(target).unsqueeze(1).float()\n",
    "\n",
    "# **3️⃣ Create DataLoader**\n",
    "dataset = TensorDataset(X, y)\n",
    "dataloader = DataLoader(dataset, batch_size=32, shuffle=True)\n",
    "\n",
    "# **4️⃣ Initialize Model, Loss, and Optimizer**\n",
    "model = BinaryClassifier()\n",
    "criterion = nn.BCELoss()  # Binary Cross Entropy Loss\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "# **5️⃣ Train the Model**\n",
    "num_epochs = 3\n",
    "for epoch in range(num_epochs):\n",
    "    for batch_X, batch_y in dataloader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_X)\n",
    "        loss = criterion(outputs, batch_y)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    print(f\"Epoch {epoch+1}, Loss: {loss.item():.4f}\")\n",
    "\n",
    "# **6️⃣ Save the Model**\n",
    "model_path = \"/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/Forschungsfest/classifier.pth\"\n",
    "torch.save({'model_state_dict': model.state_dict(),\n",
    "            'optimizer_state_dict': optimizer.state_dict(),\n",
    "            'epoch': num_epochs}, model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# **7️⃣ Load the Model**\n",
    "def load_model(model_path, input_size=2048):\n",
    "    model = BinaryClassifier(input_size)\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.001)  # Define optimizer again\n",
    "\n",
    "    checkpoint = torch.load(model_path)\n",
    "    model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DiagnosticFISH_package.DiagnosticFISH.src.utils import get_model_dataloader, run_model\n",
    "from DiagnosticFISH_package.DiagnosticFISH.src.dataset import SingleChannelDataset\n",
    "from mmengine.dataset import DefaultSampler, default_collate\n",
    "from torch.utils.data import DataLoader\n",
    "from mmselfsup.datasets.transforms import PackSelfSupInputs\n",
    "from DiagnosticFISH_package.DiagnosticFISH.src.transforms import CentralCutter, C_TensorCombiner\n",
    "\n",
    "\n",
    "cuda = 'cuda:2'\n",
    "\n",
    "model, _, _ = get_model_dataloader(\n",
    "    \"/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/mmselfsup_package/tools/work_dirs/home/config\", \n",
    "    num_worker=16,\n",
    "    batch_size=64,\n",
    "    device=cuda,\n",
    "    meta_keys=['n_signals', 'size_nucleus'],\n",
    ")\n",
    "\n",
    "pipeline = [\n",
    "    C_TensorCombiner(),\n",
    "    CentralCutter(size=128), \n",
    "    PackSelfSupInputs(meta_keys=[])\n",
    "]\n",
    "\n",
    "classifier = load_model(\"/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/src/Forschungsfest/classifier.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as patches\n",
    "\n",
    "out_size = (900, 1600)\n",
    "\n",
    "for i in range(3):\n",
    "    \n",
    "    n_images = 200 * (i + 1)\n",
    "    \n",
    "    # Generate the composite image and get positions\n",
    "    output, placed_idxs, placed_pos = randomly_place_cells(out_size, images, masks, n_images, max_rejections=50)\n",
    "\n",
    "    # Display the composite image\n",
    "    print(output.shape)\n",
    "    fig, ax = plt.subplots(figsize=(15, 15))\n",
    "    ax.imshow(output)\n",
    "    ax.axis('off')\n",
    "\n",
    "    # Load dataset\n",
    "    dataset = SingleChannelDataset(\n",
    "        '/home/simon_g/isilon_images_mnt/10_MetaSystems/MetaSystemsData/_simon/data/DiagnosticFISH/test_dataset.h5',\n",
    "        shuffle=False,\n",
    "        pipeline=pipeline,\n",
    "        channel_idx=1,\n",
    "        masked_idxs=placed_idxs)\n",
    "\n",
    "    dataloader = DataLoader(\n",
    "        dataset=dataset, \n",
    "        sampler=DefaultSampler(dataset, shuffle=False), \n",
    "        batch_size=64, \n",
    "        collate_fn=default_collate,\n",
    "        num_workers=16\n",
    "    )\n",
    "\n",
    "    # Set model to evaluation mode\n",
    "    model.eval()\n",
    "\n",
    "    # Run model\n",
    "    ret = run_model(model, dataloader, n_samples=500, get_images=True)\n",
    "\n",
    "    # Convert embeddings to tensor\n",
    "    X = torch.tensor(np.array(ret['embeddings'].tolist()).mean(axis=(2,3)))\n",
    "    print(X.shape)\n",
    "\n",
    "    # Get predictions\n",
    "    pred = classifier(X)  # Predicted probabilities\n",
    "    pred_labels = (pred > 0.5).int().cpu().numpy().flatten()  # Convert to binary labels (0 or 1)\n",
    "\n",
    "    # **Overlay squares based on predictions**\n",
    "    square_size = 96  # Size of the squares\n",
    "\n",
    "    for pos, label in zip(placed_pos, pred_labels):\n",
    "        color = \"green\" if label == 0 else \"red\"  # Green for 0, Red for 1\n",
    "        rect = patches.Rectangle(\n",
    "            (pos[1] - square_size // 2, pos[0] - square_size // 2),  # Center the square\n",
    "            square_size, square_size, linewidth=2, edgecolor=color, facecolor='none'\n",
    "        )\n",
    "        ax.add_patch(rect)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "    break  # Only process the first iteration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MM",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.23"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
